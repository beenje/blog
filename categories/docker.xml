<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tchut-Tchut Blog (Posts about docker)</title><link>http://beenje.github.io/blog/</link><description></description><atom:link href="http://beenje.github.io/blog/categories/docker.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2020 &lt;a href="mailto:beenje@gmail.com"&gt;Benjamin Bertrand&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Wed, 11 Mar 2020 18:05:01 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Experimenting with asyncio on a Raspberry Pi</title><link>http://beenje.github.io/blog/posts/experimenting-with-asyncio-on-a-raspberry-pi/</link><dc:creator>Benjamin Bertrand</dc:creator><description>&lt;div&gt;&lt;p&gt;In a previous post, I described how I built a &lt;a class="reference external" href="http://beenje.github.io/blog/posts/my-lego-macintosh-classic-with-raspberry-pi-and-e-paper-display"&gt;LEGO Macintosh Classic with
a Raspberry Pi and e-paper display&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For testing purpose I installed the clock demo which is part of the
&lt;a class="reference external" href="https://github.com/embeddedartists/gratis"&gt;Embedded Artists repository&lt;/a&gt;.
Of course I wanted to do more than displaying the time on this little box.
I also wanted to take advantage of the button I had integrated.&lt;/p&gt;
&lt;p&gt;One idea was to create a small web server so that I could receive and display
messages. The application would basically:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;display the time (every minute)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;when receiving a message, stop the clock and display the message&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;when the button is pressed, start the clock again&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;img alt="/images/legomac/press_button.gif" src="http://beenje.github.io/blog/images/legomac/press_button.gif"&gt;
&lt;p&gt;I don't know about you, but this really makes me think &lt;strong&gt;event loop&lt;/strong&gt;!
I learnt asynchronous programming with &lt;a class="reference external" href="http://krondo.com/an-introduction-to-asynchronous-programming-and-twisted/"&gt;Dave Peticolas Twisted Introduction&lt;/a&gt;
a few years ago. If you are not familiar with asynchronous programming, I really recommend
it. I wrote a few applications using &lt;a class="reference external" href="https://twistedmatrix.com"&gt;Twisted&lt;/a&gt; but I haven't had
the opportunity to use asyncio yet. Here is a very good occasion!&lt;/p&gt;
&lt;div class="section" id="asyncio"&gt;
&lt;h2&gt;asyncio&lt;/h2&gt;
&lt;div class="section" id="rest-api-using-aiohttp"&gt;
&lt;h3&gt;REST API using aiohttp&lt;/h3&gt;
&lt;p&gt;There are already several asyncio web frameworks to build an HTTP server.
I decided to go with &lt;a class="reference external" href="http://aiohttp.readthedocs.io/en/stable/"&gt;aiohttp&lt;/a&gt;
which is kind of the default one.&lt;/p&gt;
&lt;p&gt;Using this &lt;a class="reference external" href="http://steelkiwi.com/blog/jwt-authorization-python-part-1-practise/"&gt;tutorial&lt;/a&gt; I
wrote a simple REST API using aiohttp. It uses JSON Web Tokens which is
something else I have been wanted to try.&lt;/p&gt;
&lt;p&gt;The API has only 3 endpoints:&lt;/p&gt;
&lt;pre class="literal-block"&gt;def setup_routes(app):
    app.router.add_get('/', index)
    app.router.add_post('/login', login)
    app.router.add_post('/messages', post_message)&lt;/pre&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;/&lt;/cite&gt; to check that our token is valid&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;/login&lt;/cite&gt; to login&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;/messages&lt;/cite&gt; to post messages&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="literal-block"&gt;async def login(request):
    config = request.app['config']
    data = await request.json()
    try:
        user = data['username']
        passwd = data['password']
    except KeyError:
        return web.HTTPBadRequest(reason='Invalid arguments')
    # We have only one user hard-coded in the config file...
    if user != config['username'] or passwd != config['password']:
        return web.HTTPBadRequest(reason='Invalid credentials')
    payload = {
        'user_id': 1,
        'exp': datetime.datetime.utcnow() + datetime.timedelta(seconds=config['jwt_exp_delta_seconds'])
    }
    jwt_token = jwt.encode(payload, config['jwt_secret'], config['jwt_algorithm'])
    logger.debug(f'JWT token created for {user}')
    return web.json_response({'token': jwt_token.decode('utf-8')})


@login_required
async def post_message(request):
    if request.content_type != 'application/json':
        return web.HTTPBadRequest()
    data = await request.json()
    try:
        message = data['message']
    except KeyError:
        return web.HTTPBadRequest()
    logger.debug(f'Message received from {request.user}: {message}')
    return web.json_response({'message': message}, status=201)


@login_required
async def index(request):
    return web.json_response({'message': 'Welcome to LegoMac {}!'.format(request.user)})&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="raspberry-pi-gpio-and-asyncio"&gt;
&lt;h3&gt;Raspberry Pi GPIO and asyncio&lt;/h3&gt;
&lt;p&gt;The default Python package to control the Raspberry Pi GPIO seems to be
&lt;a class="reference external" href="https://pypi.python.org/pypi/RPi.GPIO"&gt;RPi.GPIO&lt;/a&gt;.
That's at least what is used in the &lt;a class="reference external" href="https://github.com/embeddedartists/gratis/blob/master/PlatformWithOS/demo/ImageDemoButton.py"&gt;ImageDemoButton.py from Embedded Artists&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;An alternative is the &lt;a class="reference external" href="http://abyz.co.uk/rpi/pigpio/index.html"&gt;pigpio library&lt;/a&gt;
which provides a daemon to access the Raspberry Pi GPIO via a pipe or socket interface.
And someone (Pierre Rust) already created an aysncio based Python client
for the pigpio daemon: &lt;a class="reference external" href="https://github.com/PierreRust/apigpio"&gt;apigpio&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Exactly what I needed!
It's basically a (incomplete) port of the original Python client provided
with pigpio, but far sufficient for my need. I just want to get a
notification when pressing the button on top of the screen.&lt;/p&gt;
&lt;p&gt;There is an example how to achieve that: &lt;a class="reference external" href="https://github.com/PierreRust/apigpio/blob/master/samples/gpio_notification.py"&gt;gpio_notification.py&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="e-paper-display-and-asyncio"&gt;
&lt;h3&gt;E-paper display and asyncio&lt;/h3&gt;
&lt;p&gt;The last remaining piece is to make the e-paper display play nicely with
asyncio.&lt;/p&gt;
&lt;p&gt;The EPD driver uses the fuse library. It allows the display to be
represented as a virtual directory of files. So sending a command
consists of writing to a file.&lt;/p&gt;
&lt;p&gt;There is a library to add file support to asyncio: &lt;a class="reference external" href="https://github.com/Tinche/aiofiles"&gt;aiofiles&lt;/a&gt;.
The only thing I had to do was basically to wrap the file IO in &lt;a class="reference external" href="https://github.com/embeddedartists/gratis/blob/master/PlatformWithOS/demo/EPD.py"&gt;EPD.py&lt;/a&gt;
with aiofiles:&lt;/p&gt;
&lt;pre class="literal-block"&gt;async def _command(self, c):
    async with aiofiles.open(os.path.join(self._epd_path, 'command'), 'wb') as f:
        await f.write(c)&lt;/pre&gt;
&lt;p&gt;You can't use &lt;cite&gt;await&lt;/cite&gt; in a class &lt;cite&gt;__init__&lt;/cite&gt; method. So following some recommendations
from &lt;a class="reference external" href="https://stackoverflow.com/questions/33128325/how-to-set-class-attribute-with-await-in-init"&gt;stackoverflow&lt;/a&gt;,
I used the factory pattern and moved the actions requiring some IO to a classmethod:&lt;/p&gt;
&lt;pre class="literal-block"&gt;@classmethod
async def create(cls, *args, **kwargs):
    self = EPD(*args, **kwargs)
    async with aiofiles.open(os.path.join(self._epd_path, 'version')) as f:
        version = await f.readline()
        self._version = version.rstrip('\n')
    async with aiofiles.open(os.path.join(self._epd_path, 'panel')) as f:
        line = await f.readline()
        m = self.PANEL_RE.match(line.rstrip('\n'))
        if m is None:
            raise EPDError('invalid panel string')
        ...&lt;/pre&gt;
&lt;p&gt;To create an instance of the EPD class, use:&lt;/p&gt;
&lt;pre class="literal-block"&gt;epd = await EPD.create([path='/path/to/epd'], [auto=boolean])&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="putting-everything-together-with-aiohttp"&gt;
&lt;h2&gt;Putting everything together with aiohttp&lt;/h2&gt;
&lt;div class="section" id="running-the-clock-as-a-background-task"&gt;
&lt;h3&gt;Running the clock as a background task&lt;/h3&gt;
&lt;p&gt;For the clock, I adapted the &lt;a class="reference external" href="https://github.com/embeddedartists/gratis/blob/master/PlatformWithOS/demo/Clock27.py"&gt;clock demo&lt;/a&gt;
from Embedded Artists repository.&lt;/p&gt;
&lt;p&gt;As described in aiohttp documentation I created a &lt;a class="reference external" href="http://aiohttp.readthedocs.io/en/stable/web.html#background-tasks"&gt;background task&lt;/a&gt; to display the clock
every minute:&lt;/p&gt;
&lt;pre class="literal-block"&gt;async def display_clock(app):
    """Background task to display clock every minute"""
    clock = Clock(app['epd'])
    first_start = True
    try:
        while True:
            while True:
                now = datetime.datetime.today()
                if now.second == 0 or first_start:
                    first_start = False
                    break
                await asyncio.sleep(0.5)
            logger.debug('display clock')
            await clock.display(now)
    except asyncio.CancelledError:
        logger.debug('display clock cancel')


async def start_background_tasks(app):
     app['epd'] = await EPD.create(auto=True)
     app['clock'] = app.loop.create_task(display_clock(app))


async def cleanup_background_tasks(app):
    app['clock'].cancel()
    await app['clock']


def init_app():
    """Create and return the aiohttp Application object"""
    app = web.Application()
    app.on_startup.append(start_background_tasks)
    app.on_cleanup.append(cleanup_background_tasks)
    ...&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="stop-the-clock-and-display-a-message"&gt;
&lt;h3&gt;Stop the clock and display a message&lt;/h3&gt;
&lt;p&gt;When receiving a message, I first cancel the clock background task and
send the messages to the e-paper display using &lt;cite&gt;ensure_future&lt;/cite&gt; so that
I can return a json response without having to wait for the message to be
displayed as it takes about 5 seconds:&lt;/p&gt;
&lt;pre class="literal-block"&gt;@login_required
async def post_message(request):
    if request.content_type != 'application/json':
        return web.HTTPBadRequest()
    data = await request.json()
    try:
        message = data['message']
    except KeyError:
        return web.HTTPBadRequest()
    # cancel the display clock
    request.app['clock'].cancel()
    logger.debug(f'Message received from {request.user}: {message}')
    now = datetime.datetime.now(request.app['timezone'])
    helpers.ensure_future(request.app['epd'].display_message(message, request.user, now))
    return web.json_response({'message': message}, status=201)&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="start-the-clock-when-pressing-the-button"&gt;
&lt;h3&gt;Start the clock when pressing the button&lt;/h3&gt;
&lt;p&gt;To be able to restart the clock when pressing the button, I connect to the
pigpiod when starting the app (in &lt;cite&gt;start_background_tasks&lt;/cite&gt;) and register
the &lt;cite&gt;on_input&lt;/cite&gt; callback:&lt;/p&gt;
&lt;pre class="literal-block"&gt;async def start_background_tasks(app):
    app['pi'] = apigpio.Pi(app.loop)
    address = (app['config']['pigpiod_host'], app['config']['pigpiod_port'])
    await app['pi'].connect(address)
    await app['pi'].set_mode(BUTTON_GPIO, apigpio.INPUT)
    app['cb'] = await app['pi'].add_callback(
            BUTTON_GPIO,
            edge=apigpio.RISING_EDGE,
            func=functools.partial(on_input, app))
    ...&lt;/pre&gt;
&lt;p&gt;In the &lt;cite&gt;on_input&lt;/cite&gt; callback, I re-create the clock background task but only if the previous
task is done:&lt;/p&gt;
&lt;pre class="literal-block"&gt;def on_input(app, gpio, level, tick):
    """Callback called when pressing the button on the e-paper display"""
    logger.info('on_input {} {} {}'.format(gpio, level, tick))
    if app['clock'].done():
        logger.info('restart clock')
        app['clock'] = app.loop.create_task(display_clock(app))&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="running-on-the-pi"&gt;
&lt;h2&gt;Running on the Pi&lt;/h2&gt;
&lt;p&gt;You might have noticed that I used some syntax that is Python 3.6 only.
I don't really see myself using something else when starting a new project
today :-)
There are so many new things (like f-strings) that make your programs look
cleaner.&lt;/p&gt;
&lt;p&gt;On raspbian, if you install Python 3, you get 3.4... So how do you get Python 3.6 on
a Raspberry Pi?&lt;/p&gt;
&lt;p&gt;On desktop/server I usually use &lt;a class="reference external" href="https://conda.io/miniconda.html"&gt;conda&lt;/a&gt;. It makes it so easy to install
the Python version you want and many dependencies.
There are no official installer for the armv6 architecture but I
found &lt;a class="reference external" href="https://github.com/jjhelmus/berryconda"&gt;berryconda&lt;/a&gt; which is a
conda based distribution for the Raspberry Pi! Really nice!&lt;/p&gt;
&lt;p&gt;Another alternative is to use &lt;a class="reference external" href="https://www.docker.com"&gt;docker&lt;/a&gt;.
There are official &lt;a class="reference external" href="https://hub.docker.com/u/arm32v6/python"&gt;arm32v6 images&lt;/a&gt;
based on alpine and some from &lt;a class="reference external" href="https://hub.docker.com/r/resin/raspberry-pi-python/"&gt;resin.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I could have gone with berryconda, but there's one thing I wanted as well.
I'll have to open the HTTP server to the outside world meaning I need
HTTPS. As mentionned in another &lt;a class="reference external" href="http://beenje.github.io/blog/post/running-your-application-over-https-with-traefik"&gt;post&lt;/a&gt;, &lt;a class="reference external" href="https://traefik.io"&gt;traefik&lt;/a&gt; makes
that very easy if you use docker. So that's what I chose.&lt;/p&gt;
&lt;p&gt;I created 3 containers:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;traefik&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;pigpiod&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;aiolegomac&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="traefik"&gt;
&lt;h3&gt;traefik&lt;/h3&gt;
&lt;p&gt;There are no official Traefik docker images for arm yet, but an &lt;a class="reference external" href="https://github.com/containous/traefik/issues/1665"&gt;issue&lt;/a&gt; is currently opened.
So it should arrive soon!&lt;/p&gt;
&lt;p&gt;In the meantime I created my own:&lt;/p&gt;
&lt;pre class="literal-block"&gt;FROM arm32v6/alpine:3.6

RUN apk --update upgrade \
  &amp;amp;&amp;amp; apk --no-cache --no-progress add ca-certificates \
  &amp;amp;&amp;amp; apk add openssl \
  &amp;amp;&amp;amp; rm -rf /var/cache/apk/*

RUN wget -O /usr/local/bin/traefik https://github.com/containous/traefik/releases/download/v1.3.3/traefik_linux-arm \
  &amp;amp;&amp;amp; chmod a+x /usr/local/bin/traefik

ENTRYPOINT ["/usr/local/bin/traefik"]&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="pigpiod"&gt;
&lt;h3&gt;pigpiod&lt;/h3&gt;
&lt;p&gt;For pigpiod, I first created an image based on &lt;cite&gt;arm32v6/alpine&lt;/cite&gt; but I noticed I couldn't send
a SIGTERM to the daemon to stop it properly... I'm not sure why. Alpine being based on &lt;cite&gt;musl&lt;/cite&gt; instead
of &lt;cite&gt;glibc&lt;/cite&gt; might be the problem. Here is the Dockerfile I tried:&lt;/p&gt;
&lt;pre class="literal-block"&gt;FROM arm32v6/alpine:3.6

RUN apk add --no-cache --virtual .build-deps \
  gcc \
  make \
  musl-dev \
  tar \
  &amp;amp;&amp;amp; wget -O /tmp/pigpio.tar abyz.co.uk/rpi/pigpio/pigpio.tar \
  &amp;amp;&amp;amp; tar -xf /tmp/pigpio.tar -C /tmp \
  &amp;amp;&amp;amp; sed -i "/ldconfig/d" /tmp/PIGPIO/Makefile \
  &amp;amp;&amp;amp; make -C /tmp/PIGPIO \
  &amp;amp;&amp;amp; make -C /tmp/PIGPIO install \
  &amp;amp;&amp;amp; rm -rf /tmp/PIGPIO /tmp/pigpio.tar \
  &amp;amp;&amp;amp; apk del .build-deps

EXPOSE 8888

ENTRYPOINT ["/usr/local/bin/pigpiod", "-g"]&lt;/pre&gt;
&lt;p&gt;I even tried using &lt;a class="reference external" href="https://github.com/krallin/tini"&gt;tini&lt;/a&gt; as entrypoint without luck.
So if someone as the explanation, please share it in the comments.&lt;/p&gt;
&lt;p&gt;I tried with &lt;cite&gt;resin/rpi-raspbian&lt;/cite&gt; image and I got it working properly right away:&lt;/p&gt;
&lt;pre class="literal-block"&gt;FROM resin/rpi-raspbian:jessie

RUN apt-get update \
  &amp;amp;&amp;amp; apt-get install -y \
     make \
     gcc \
     libc6-dev \
  &amp;amp;&amp;amp; apt-get clean \
  &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*

RUN curl -o /tmp/pigpio.tar abyz.co.uk/rpi/pigpio/pigpio.tar \
  &amp;amp;&amp;amp; tar -xf /tmp/pigpio.tar -C /tmp \
  &amp;amp;&amp;amp; make -C /tmp/PIGPIO \
  &amp;amp;&amp;amp; make -C /tmp/PIGPIO install \
  &amp;amp;&amp;amp; rm -rf /tmp/pigpio.tar /tmp/PIGPIO

EXPOSE 8888

ENTRYPOINT ["/usr/local/bin/pigpiod", "-g"]&lt;/pre&gt;
&lt;p&gt;Note that the container has to run in privileged mode to access the GPIO.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="aiolegomac"&gt;
&lt;h3&gt;aiolegomac&lt;/h3&gt;
&lt;p&gt;For the main application, the Dockerfile is quite standard for a Python application:&lt;/p&gt;
&lt;pre class="literal-block"&gt;FROM resin/raspberry-pi-python:3.6

RUN apt-get update \
  &amp;amp;&amp;amp; apt-get install -y \
     fonts-liberation \
     fonts-dejavu  \
     libjpeg-dev \
     libfreetype6-dev \
     libtiff5-dev \
     liblcms2-dev \
     libwebp-dev \
     zlib1g-dev \
     libyaml-0-2 \
  &amp;amp;&amp;amp; apt-get autoremove \
  &amp;amp;&amp;amp; apt-get clean \
  &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY requirements.txt /app/requirements.txt
RUN python -m venv /opt/legomac \
  &amp;amp;&amp;amp; /opt/legomac/bin/pip install -r requirements.txt

COPY . /app

ENTRYPOINT ["/opt/legomac/bin/python"]
CMD ["run.py"]&lt;/pre&gt;
&lt;p&gt;What about the EPD driver?
As it uses libfuse to represent the e-paper display as a virtual directory of files,
the easiest was to install it on the host and to mount it as a volume inside the docker
container.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="deployment"&gt;
&lt;h2&gt;Deployment&lt;/h2&gt;
&lt;p&gt;To install all that on the Pi, I wrote a small &lt;a class="reference external" href="https://www.ansible.com"&gt;Ansible&lt;/a&gt; playbook.&lt;/p&gt;
&lt;ol class="arabic"&gt;
&lt;li&gt;&lt;p&gt;Configure the Pi as described in my &lt;a class="reference external" href="http://beenje.github.io/blog/posts/my-lego-macintosh-classic-with-raspberry-pi-and-e-paper-display"&gt;previous post&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Clone the playbook:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ git clone https://github.com/beenje/legomac.git
$ cd legomac&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a file &lt;cite&gt;host_vars/legomac&lt;/cite&gt; with your variables (assuming the hostname of the Pi is legomac):&lt;/p&gt;
&lt;pre class="literal-block"&gt;aiolegomac_hostname: myhost.example.com
aiolegomac_username: john
aiolegomac_password: mypassword
aiolegomac_jwt_secret: secret
traefik_letsencrypt_email: youremail@example.com
traefik_letsencrypt_production: true&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run the playbook:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ ansible-playbook -i hosts -k playbook.yml&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This will install docker and the EPD driver, download the &lt;a class="reference external" href="https://github.com/beenje/aiolegomac"&gt;aiolegomac repository&lt;/a&gt;, build the 3 docker images
and start everything.&lt;/p&gt;
&lt;p&gt;Building the main application docker image on a Raspberry Pi Zero takes quite some time.
So be patient :-) Just go and do something else.&lt;/p&gt;
&lt;p&gt;When the full playbook is complete (it took about 55 minutes for me),
you'll have a server with HTTPS support (thanks to Let's Encrypt) running on the Pi. It's displaying
the clock every minute and you can send messages to it!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="client"&gt;
&lt;h2&gt;Client&lt;/h2&gt;
&lt;div class="section" id="httpie"&gt;
&lt;h3&gt;HTTPie&lt;/h3&gt;
&lt;p&gt;To test the server you can of course use &lt;a class="reference external" href="https://curl.haxx.se"&gt;curl&lt;/a&gt;
but I really like &lt;a class="reference external" href="https://httpie.org"&gt;HTTPie&lt;/a&gt;. It's much more user
friendly.&lt;/p&gt;
&lt;p&gt;Let's try to access our new server:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ http GET https://myhost.example.com
HTTP/1.1 401 Unauthorized
Content-Length: 25
Content-Type: application/json; charset=utf-8
Date: Sun, 16 Jul 2017 06:22:42 GMT
Server: Python/3.6 aiohttp/2.2.3

{
    "error": "Unauthorized"
}&lt;/pre&gt;
&lt;p&gt;Good, we need to login:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ http POST https://myhost.example.com/login username=john password=foo
HTTP/1.1 400 Bad Request
Content-Length: 32
Content-Type: application/json; charset=utf-8
Date: Sun, 16 Jul 2017 06:18:39 GMT
Server: Python/3.6 aiohttp/2.2.3

{
    "error": "Invalid credentials"
}&lt;/pre&gt;
&lt;p&gt;Oops, wrong password:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ http POST https://myhost.example.com/login username=john password='mypassword'
HTTP/1.1 200 OK
Content-Length: 134
Content-Type: application/json; charset=utf-8
Date: Sun, 16 Jul 2017 06:21:14 GMT
Server: Python/3.6 aiohttp/2.2.3

{
    "token": "eyK0eXAiOiJRV5QiLCJhbGciOiJIUzI1NiJ9.eyJ1c3VyX2lkIjoxLCJleHAiOjE1MDB5MTIwOTh9.hECnj4u2mxvZ2r8IEC-db1T-eKTplM4kWJKZoHhtLxQ"
}&lt;/pre&gt;
&lt;p&gt;We got a token that we can use:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ http GET https://myhost.example.com 'Authorization: eyK0eXAiOiJRV5QiLCJhbGciOiJIUzI1NiJ9.eyJ1c3VyX2lkIjoxLCJleHAiOjE1MDB5MTIwOTh9.hECnj4u2mxvZ2r8IEC-db1T-eKTplM4kWJKZoHhtLxQ'
HTTP/1.1 200 OK
Content-Length: 43
Content-Type: application/json; charset=utf-8
Date: Sun, 16 Jul 2017 06:22:25 GMT
Server: Python/3.6 aiohttp/2.2.3

{
    "message": "Welcome to LegoMac john!"
}&lt;/pre&gt;
&lt;p&gt;Authentication is working, so we can send a message:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ http POST https://myhost.example.com/messages message='Hello World!' 'Authorization: eyK0eXAiOiJRV5QiLCJhbGciOiJIUzI1NiJ9.eyJ1c3VyX2lkIjoxLCJleHAiOjE1MDB5MTIwOTh9.hECnj4u2mxvZ2r8IEC-db1T-eKTplM4kWJKZoHhtLxQ'
HTTP/1.1 201 Created
Content-Length: 27
Content-Type: application/json; charset=utf-8
Date: Sun, 16 Jul 2017 06:23:46 GMT
Server: Python/3.6 aiohttp/2.2.3

{
    "message": "Hello World!"
}&lt;/pre&gt;
&lt;p&gt;Message sent!
HTTPie is nice for testing, but we can make a small script to easily send messages from the command line.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="requests"&gt;
&lt;h3&gt;requests&lt;/h3&gt;
&lt;p&gt;&lt;a class="reference external" href="http://docs.python-requests.org"&gt;requests&lt;/a&gt; is of course the HTTP library to use in Python.&lt;/p&gt;
&lt;p&gt;So let's write a small script to send messages to our server.
We'll store the server url and username to use in a small yaml configuration file.
If we don't have a token yet or if the saved one is no longer valid,
the script will retrieve one after prompting us for a password.
The token is saved in the configuration file for later use.&lt;/p&gt;
&lt;p&gt;The following script could be improved with some nicer error messages
by catching exceptions. But it does the job:&lt;/p&gt;
&lt;pre class="literal-block"&gt;import os
import click
import requests
import yaml


def get_config(filename):
    with open(filename) as f:
        config = yaml.load(f)
    return config


def save_config(filename, config):
    with open(filename, 'w') as f:
        yaml.dump(config, f, default_flow_style=False)


def get_token(url, username):
    password = click.prompt('Password', hide_input=True)
    payload = {'username': username, 'password': password}
    r = requests.post(url + '/login', json=payload)
    r.raise_for_status()
    return r.json()['token']


def send_message(url, token, message):
    payload = {'message': message}
    headers = {'Authorization': token}
    r = requests.post(url + '/messages', json=payload, headers=headers)
    r.raise_for_status()


@click.command()
@click.option('--conf', '-c', default='~/.pylegomac.yml',
              help='Configuration file [default: "~/.pylegomac.yml"]')
@click.argument('message')
@click.version_option()
def pylegomac(message, conf):
    """Send message to aiolegomac server"""
    filename = os.path.expanduser(conf)
    config = get_config(filename)
    url = config['url']
    username = config['username']
    if 'token' in config:
        try:
            send_message(url, config['token'], message)
        except requests.exceptions.HTTPError as err:
            # Token no more valid
            pass
        else:
            click.echo('Message sent')
            return
    token = get_token(url, username)
    send_message(url, token, message)
    config['token'] = token
    save_config(filename, config)


if __name__ == '__main__':
    pylegomac()&lt;/pre&gt;
&lt;p&gt;Let's first create a configuration file:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ cat ~/.pylegomac.yml
url: https://myhost.example.com
username: john&lt;/pre&gt;
&lt;p&gt;Send a message:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ python pylegomac.py 'Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated.'
Password:
Message sent&lt;/pre&gt;
&lt;img alt="/images/legomac/zen_of_python.jpg" src="http://beenje.github.io/blog/images/legomac/zen_of_python.jpg"&gt;
&lt;p&gt;Sending a new message won't request the password as the token was saved in the config file.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I have a nice little aiohttp server running on my Raspberry Pi that can receive and display messages.
asyncio is quite pleasant to work with. I really like the async/await syntax.&lt;/p&gt;
&lt;p&gt;All the code is on github:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/beenje/aiolegomac"&gt;aiolegomac&lt;/a&gt; (the server and client script)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/beenje/legomac"&gt;legomac&lt;/a&gt; (the Ansible playbook to deploy the server)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Why did I only write a command line script to send messages and no web interface?
Don't worry, that's planned! I could have used Jinja2. But I'd like to try a javascript framework.
So that will be the subject of another post.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>Ansible</category><category>docker</category><category>lego</category><category>pi</category><category>python</category><guid>http://beenje.github.io/blog/posts/experimenting-with-asyncio-on-a-raspberry-pi/</guid><pubDate>Tue, 18 Jul 2017 20:46:17 GMT</pubDate></item><item><title>Dockerfile anti-patterns and best practices</title><link>http://beenje.github.io/blog/posts/dockerfile-anti-patterns-and-best-practices/</link><dc:creator>Benjamin Bertrand</dc:creator><description>&lt;div&gt;&lt;p&gt;I've been using &lt;a class="reference external" href="https://www.docker.com"&gt;Docker&lt;/a&gt; for some time now.
There is already a lot of documentation available online but I recently
saw the same "anti-patterns" several times, so I thought it was worth writing a post about
it.&lt;/p&gt;
&lt;p&gt;I won't repeat all the &lt;a class="reference external" href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/"&gt;Best practices for writing Dockerfiles&lt;/a&gt; here.
You should definitively read that page.&lt;/p&gt;
&lt;p&gt;I want to emphasize some things that took me some time to understand.&lt;/p&gt;
&lt;div class="section" id="avoid-invalidating-the-cache"&gt;
&lt;h2&gt;Avoid invalidating the cache&lt;/h2&gt;
&lt;p&gt;Let's take a simple example with a Python application:&lt;/p&gt;
&lt;pre class="literal-block"&gt;FROM python:3.6

COPY . /app
WORKDIR /app

RUN pip install -r requirements.txt

ENTRYPOINT ["python"]
CMD ["ap.py"]&lt;/pre&gt;
&lt;p&gt;It's actually an example I have seen several times online.
This looks fine, right?&lt;/p&gt;
&lt;p&gt;The problem is that the &lt;em&gt;COPY . /app&lt;/em&gt; command will invalidate the cache as
soon as any file in the current directory is updated.
Let's say you just change the &lt;em&gt;README&lt;/em&gt; file and run &lt;em&gt;docker build&lt;/em&gt; again.
Docker will have to re-install all the requirements because the
&lt;em&gt;RUN pip&lt;/em&gt; command is run after the &lt;em&gt;COPY&lt;/em&gt; that invalidated the cache.&lt;/p&gt;
&lt;p&gt;The requirements should only be re-installed if the &lt;em&gt;requirements.txt&lt;/em&gt;
file changes:&lt;/p&gt;
&lt;pre class="literal-block"&gt;FROM python:3.6

WORKDIR /app

COPY requirements.txt /app/requirements.txt
RUN pip install -r requirements.txt

COPY . /app

ENTRYPOINT ["python"]
CMD ["ap.py"]&lt;/pre&gt;
&lt;p&gt;With this Dockerfile, the &lt;em&gt;RUN pip&lt;/em&gt; command will only be re-run when the
&lt;em&gt;requirements.txt&lt;/em&gt; file changes. It will use the cache otherwise.&lt;/p&gt;
&lt;p&gt;This is much more efficient and will save you quite some time if you have
many requirements to install.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="minimize-the-number-of-layers"&gt;
&lt;h2&gt;Minimize the number of layers&lt;/h2&gt;
&lt;p&gt;What does that really mean?&lt;/p&gt;
&lt;p&gt;Each &lt;a class="reference external" href="https://www.docker.com"&gt;Docker&lt;/a&gt; image references a list of read-only layers that represent
filesystem differences. Every command in your Dockerfile will create a new
layer.&lt;/p&gt;
&lt;p&gt;Let's use the following Dockerfile:&lt;/p&gt;
&lt;pre class="literal-block"&gt;FROM centos:7

RUN yum update -y
RUN yum install -y sudo
RUN yum install -y git
RUN yum clean all&lt;/pre&gt;
&lt;p&gt;Build the docker image and check the layers created with the &lt;em&gt;docker history&lt;/em&gt; command:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ docker build -t centos-test .
...
$ docker images
REPOSITORY                       TAG                 IMAGE ID            CREATED              SIZE
centos-test                      latest              1fae366a2613        About a minute ago   470 MB
centos                           7                   98d35105a391        24 hours ago         193 MB
$ docker history centos-test
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
1fae366a2613        2 minutes ago       /bin/sh -c yum clean all                        1.67 MB
999e7c7c0e14        2 minutes ago       /bin/sh -c yum install -y git                   133 MB
c97b66528792        3 minutes ago       /bin/sh -c yum install -y sudo                  81 MB
e0c7b450b7a8        3 minutes ago       /bin/sh -c yum update -y                        62.5 MB
98d35105a391        24 hours ago        /bin/sh -c #(nop)  CMD ["/bin/bash"]            0 B
&amp;lt;missing&amp;gt;           24 hours ago        /bin/sh -c #(nop)  LABEL name=CentOS Base ...   0 B
&amp;lt;missing&amp;gt;           24 hours ago        /bin/sh -c #(nop) ADD file:29f66b8b4bafd0f...   193 MB
&amp;lt;missing&amp;gt;           6 months ago        /bin/sh -c #(nop)  MAINTAINER https://gith...   0 B&lt;/pre&gt;
&lt;p&gt;There are two problems with this Dockerfile:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;We added too many layers for nothing.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;em&gt;yum clean all&lt;/em&gt; command is meant to reduce the size of the image but it
actually does the opposite by adding a new layer!&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let's check that by removing the latest command and running the build
again:&lt;/p&gt;
&lt;pre class="literal-block"&gt;FROM centos:7

RUN yum update -y
RUN yum install -y sudo
RUN yum install -y git
# RUN yum clean all&lt;/pre&gt;
&lt;pre class="literal-block"&gt;$ docker build -t centos-test .
...
$ docker images
REPOSITORY                       TAG                 IMAGE ID            CREATED             SIZE
centos-test                      latest              999e7c7c0e14        11 minutes ago      469 MB
centos                           7                   98d35105a391        24 hours ago        193 MB&lt;/pre&gt;
&lt;p&gt;The new image without the &lt;em&gt;yum clean all&lt;/em&gt; command is indeed smaller than the previous image (1.67 MB smaller)!&lt;/p&gt;
&lt;p&gt;If you want to remove files, it's important to do that in the same RUN command that created those files.
Otherwise there is no point.&lt;/p&gt;
&lt;p&gt;Here is the proper way to do it:&lt;/p&gt;
&lt;pre class="literal-block"&gt;FROM centos:7

RUN yum update -y \
  &amp;amp;&amp;amp; yum install -y \
  sudo \
  git \
  &amp;amp;&amp;amp; yum clean all&lt;/pre&gt;
&lt;p&gt;Let's build this new image:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ docker build -t centos-test .
...
$ docker images
REPOSITORY                       TAG                 IMAGE ID            CREATED             SIZE
centos-test                      latest              54a328ef7efd        21 seconds ago      265 MB
centos                           7                   98d35105a391        24 hours ago        193 MB
$ docker history centos-test
IMAGE               CREATED              CREATED BY                                      SIZE                COMMENT
54a328ef7efd        About a minute ago   /bin/sh -c yum update -y   &amp;amp;&amp;amp; yum install ...   72.8 MB
98d35105a391        24 hours ago         /bin/sh -c #(nop)  CMD ["/bin/bash"]            0 B
&amp;lt;missing&amp;gt;           24 hours ago         /bin/sh -c #(nop)  LABEL name=CentOS Base ...   0 B
&amp;lt;missing&amp;gt;           24 hours ago         /bin/sh -c #(nop) ADD file:29f66b8b4bafd0f...   193 MB
&amp;lt;missing&amp;gt;           6 months ago         /bin/sh -c #(nop)  MAINTAINER https://gith...   0 B&lt;/pre&gt;
&lt;p&gt;The new image is only 265 MB compared to the 470 MB of the original image.
There isn't much more to say :-)&lt;/p&gt;
&lt;p&gt;If you want to know more about images and layers, you should read the
documentation: &lt;a class="reference external" href="https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers/"&gt;Understand images, containers, and storage drivers&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Avoid invalidating the cache:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;start your Dockerfile with commands that should not change often&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;put commands that can often invalidate the cache (like COPY .) as
late as possible&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;only add the needed files (use a .dockerignore file)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Minimize the number of layers:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;put related commands in the same RUN instruction&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;remove files in the same RUN command that created them&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>docker</category><guid>http://beenje.github.io/blog/posts/dockerfile-anti-patterns-and-best-practices/</guid><pubDate>Thu, 16 Mar 2017 21:10:49 GMT</pubDate></item><item><title>Docker and conda</title><link>http://beenje.github.io/blog/posts/docker-and-conda/</link><dc:creator>Benjamin Bertrand</dc:creator><description>&lt;div&gt;&lt;p&gt;I just read a blog post about &lt;a class="reference external" href="http://fmgdata.kinja.com/using-docker-with-conda-environments-1790901398"&gt;Using Docker with Conda Environments&lt;/a&gt;.
I do things slightly differently so I thought I would share an example of
Dockerfile I use:&lt;/p&gt;
&lt;pre class="literal-block"&gt;FROM continuumio/miniconda3:latest

# Install extra packages if required
RUN apt-get update &amp;amp;&amp;amp; apt-get install -y \
    xxxxxx \
    &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*

# Add the user that will run the app (no need to run as root)
RUN groupadd -r myuser &amp;amp;&amp;amp; useradd -r -g myuser myuser

WORKDIR /app

# Install myapp requirements
COPY environment.yml /app/environment.yml
RUN conda config --add channels conda-forge \
    &amp;amp;&amp;amp; conda env create -n myapp -f environment.yml \
    &amp;amp;&amp;amp; rm -rf /opt/conda/pkgs/*

# Install myapp
COPY . /app/
RUN chown -R myuser:myuser /app/*

# activate the myapp environment
ENV PATH /opt/conda/envs/myapp/bin:$PATH&lt;/pre&gt;
&lt;p&gt;I don't run &lt;cite&gt;source activate myapp&lt;/cite&gt; but just use &lt;cite&gt;ENV&lt;/cite&gt; to update the &lt;cite&gt;PATH&lt;/cite&gt;
variable. There is only one environment in the docker image. No need for the extra
checks done by the activate script.&lt;/p&gt;
&lt;p&gt;With this Dockerfile, any command will be run in the &lt;cite&gt;myapp&lt;/cite&gt;
environment.&lt;/p&gt;
&lt;p&gt;Just a few additional notes:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;Be sure to only copy the file &lt;cite&gt;environment.yml&lt;/cite&gt; before to copy the full
current directory. Otherwise any change in the directory would
invalidate the docker cache.
We only want to re-create the conda environment if &lt;cite&gt;environment.yml&lt;/cite&gt;
changes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I always add the &lt;a class="reference external" href="https://conda-forge.github.io"&gt;conda-forge channel&lt;/a&gt;.
Check this &lt;a class="reference external" href="https://www.continuum.io/blog/developer-blog/community-conda-forge"&gt;post&lt;/a&gt;
if you haven't heard of it yet.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I clean some cache (&lt;em&gt;/var/lib/apt/lists/&lt;/em&gt; and &lt;em&gt;/opt/conda/pkgs/&lt;/em&gt;) to
make the image a bit smaller.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I switched from virtualenv to &lt;a class="reference external" href="https://conda.io"&gt;conda&lt;/a&gt; a while ago and I really enjoy it.
A big thanks to &lt;a class="reference external" href="https://www.continuum.io"&gt;Continuum Analytics&lt;/a&gt;!&lt;/p&gt;&lt;/div&gt;</description><category>conda</category><category>docker</category><category>python</category><guid>http://beenje.github.io/blog/posts/docker-and-conda/</guid><pubDate>Sat, 28 Jan 2017 22:32:56 GMT</pubDate></item><item><title>GitLab Container Registry and proxy</title><link>http://beenje.github.io/blog/posts/gitlab-container-registry-and-proxy/</link><dc:creator>Benjamin Bertrand</dc:creator><description>&lt;div&gt;&lt;div class="section" id="gitlab-on-synology"&gt;
&lt;h2&gt;GitLab on Synology&lt;/h2&gt;
&lt;p&gt;I installed GitLab CE on a Synology RackStation RS815+ at work.
It has an Intel Atom C2538 that allows to run &lt;a class="reference external" href="https://www.docker.com"&gt;Docker&lt;/a&gt; on the NAS.&lt;/p&gt;
&lt;p&gt;Official GitLab Community Edition docker images are available on &lt;a class="reference external" href="https://hub.docker.com/r/gitlab/gitlab-ce/"&gt;Docker Hub&lt;/a&gt;.
The documentation to use the image is quite clear and can be found &lt;a class="reference external" href="https://docs.gitlab.com/omnibus/docker/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The ports 80 and 443 are already used by nginx that comes with &lt;a class="reference external" href="https://www.synology.com/en-global/dsm/6.0"&gt;DSM&lt;/a&gt;.
I wanted to access GitLab using HTTPS, so I disabled port 443 in nginx
configuration. To do that I had to modify the template
&lt;cite&gt;/usr/syno/share/nginx/WWWService.mustache&lt;/cite&gt; and reboot the NAS:&lt;/p&gt;
&lt;pre class="code diff"&gt;&lt;a name="rest_code_7870ce14df8241a4b6006e19315a25dc-1"&gt;&lt;/a&gt;&lt;span class="gd"&gt;--- WWWService.mustache.org 2016-08-16 23:25:06.000000000 +0100&lt;/span&gt;
&lt;a name="rest_code_7870ce14df8241a4b6006e19315a25dc-2"&gt;&lt;/a&gt;&lt;span class="gi"&gt;+++ WWWService.mustache 2016-09-19 13:53:45.256735700 +0100&lt;/span&gt;
&lt;a name="rest_code_7870ce14df8241a4b6006e19315a25dc-3"&gt;&lt;/a&gt;&lt;span class="gu"&gt;@@ -1,8 +1,6 @@&lt;/span&gt;
&lt;a name="rest_code_7870ce14df8241a4b6006e19315a25dc-4"&gt;&lt;/a&gt; server {
&lt;a name="rest_code_7870ce14df8241a4b6006e19315a25dc-5"&gt;&lt;/a&gt;     listen 80 default_server{{#reuseport}} reuseport{{/reuseport}};
&lt;a name="rest_code_7870ce14df8241a4b6006e19315a25dc-6"&gt;&lt;/a&gt;     listen [::]:80 default_server{{#reuseport}} reuseport{{/reuseport}};
&lt;a name="rest_code_7870ce14df8241a4b6006e19315a25dc-7"&gt;&lt;/a&gt;&lt;span class="gd"&gt;-    listen 443 default_server ssl{{#reuseport}} reuseport{{/reuseport}};&lt;/span&gt;
&lt;a name="rest_code_7870ce14df8241a4b6006e19315a25dc-8"&gt;&lt;/a&gt;&lt;span class="gd"&gt;-    listen [::]:443 default_server ssl{{#reuseport}} reuseport{{/reuseport}};&lt;/span&gt;
&lt;a name="rest_code_7870ce14df8241a4b6006e19315a25dc-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_7870ce14df8241a4b6006e19315a25dc-10"&gt;&lt;/a&gt;     server_name _;
&lt;/pre&gt;&lt;p&gt;The port 22 is also already used by the ssh daemon so I decided to use
the port 2222. I created the directory &lt;cite&gt;/volume1/docker/gitlab&lt;/cite&gt; to store
all GitLab data. Here are the required variables in the
&lt;cite&gt;/volume1/docker/gitlab/config/gitlab.rb&lt;/cite&gt; config file:&lt;/p&gt;
&lt;pre class="literal-block"&gt;external_url "https://mygitlab.example.com"

## GitLab Shell settings for GitLab
gitlab_rails['gitlab_shell_ssh_port'] = 2222

nginx['enable'] = true
nginx['redirect_http_to_https'] = true&lt;/pre&gt;
&lt;p&gt;And this is how I run the image:&lt;/p&gt;
&lt;pre class="literal-block"&gt;docker run --detach \
    --hostname mygitlab.example.com \
    --publish 443:443 --publish 8080:80 --publish 2222:22 \
    --name gitlab \
    --restart always \
    --volume /volume1/docker/gitlab/config:/etc/gitlab \
    --volume /volume1/docker/gitlab/logs:/var/log/gitlab \
    --volume /volume1/docker/gitlab/data:/var/opt/gitlab \
    gitlab/gitlab-ce:latest&lt;/pre&gt;
&lt;p&gt;This has been working fine. Since I heard about &lt;a class="reference external" href="https://about.gitlab.com/2016/05/23/gitlab-container-registry/"&gt;GitLab Container Registry&lt;/a&gt;,
I've been wanted to give it a try.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;GitLab Container Registry&lt;/h2&gt;
&lt;p&gt;To enable it, I just added to my &lt;cite&gt;gitlab.rb&lt;/cite&gt; file the registry url:&lt;/p&gt;
&lt;pre class="literal-block"&gt;registry_external_url 'https://mygitlab.example.com:4567'&lt;/pre&gt;
&lt;p&gt;I use the existing GitLab domain and use the port 4567 for the registry.
The TLS certificate and key are in the default path, so no need to specify them.&lt;/p&gt;
&lt;p&gt;So let's restart GitLab. Don't forget to publish the new port 4567!&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ docker stop gitlab
$ docker rm gitlab
$ docker run --detach \
    --hostname mygitlab.example.com \
    --publish 443:443 --publish 8080:80 --publish 2222:22 \
    --publish 4567:4567 \
    --name gitlab \
    --restart always \
    --volume /volume1/docker/gitlab/config:/etc/gitlab \
    --volume /volume1/docker/gitlab/logs:/var/log/gitlab \
    --volume /volume1/docker/gitlab/data:/var/opt/gitlab \
    gitlab/gitlab-ce:latest&lt;/pre&gt;
&lt;p&gt;Easy! Let's test our new docker registry!&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ docker login mygitlab.example.com:4567
Username: user
Password:
Error response from daemon: Get https://mygitlab.example.com:4567/v1/users/: Service Unavailable&lt;/pre&gt;
&lt;p&gt;Hmm... Not super useful error...
I thought about publishing port 4567 in docker, so what is happening?
After looking through the logs, I found &lt;cite&gt;/volume1/docker/gitlab/logs/nginx/gitlab_registry_access.logi&lt;/cite&gt;. It's empty...
Let's try curl:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ curl https://mygitlab.example.com:4567/v1/users/

curl: (60) Peer certificate cannot be authenticated with known CA certificates
More details here: http://curl.haxx.se/docs/sslcerts.html

curl performs SSL certificate verification by default, using a "bundle"
 of Certificate Authority (CA) public keys (CA certs). If the default
 bundle file isn't adequate, you can specify an alternate file
 using the --cacert option.
If this HTTPS server uses a certificate signed by a CA represented in
 the bundle, the certificate verification probably failed due to a
 problem with the certificate (it might be expired, or the name might
 not match the domain name in the URL).
If you'd like to turn off curl's verification of the certificate, use
 the -k (or --insecure) option.&lt;/pre&gt;
&lt;p&gt;OK, I have a self-signed certificate. So let's try with &lt;cite&gt;--insecure&lt;/cite&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ curl --insecure https://mygitlab.example.com:4567/v1/users/
404 page not found&lt;/pre&gt;
&lt;p&gt;At least I get an entry in my log file:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ cd /volume1/docker/gitlab
$ cat logs/nginx/gitlab_registry_access.log
xxx.xx.x.x - - [21/Sep/2016:14:24:57 +0000] "GET /v1/users/ HTTP/1.1" 404 19 "-" "curl/7.43.0"&lt;/pre&gt;
&lt;p&gt;So, docker and nginx seem to be configured properly...
It looks like &lt;cite&gt;docker login&lt;/cite&gt; is not even trying to access my host...&lt;/p&gt;
&lt;p&gt;Let's try with a dummy host:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ docker login foo
Username: user
Password:
Error response from daemon: Get https://mygitlab.example.com:4567/v1/users/: Service Unavailable&lt;/pre&gt;
&lt;p&gt;Same error!
Why is that? I can ping &lt;cite&gt;mygitlab.example.com&lt;/cite&gt; and even access nginx on port 4567 (using curl)
inside the docker container...
My machine is on the same network. It can't be a proxy problem. Wait. Proxy?&lt;/p&gt;
&lt;p&gt;That's when I remembered I had configured my docker daemon to use a proxy to access the internet!
I created the file &lt;cite&gt;/etc/systemd/system/docker.service.d/http-proxy.conf&lt;/cite&gt; with:&lt;/p&gt;
&lt;pre class="literal-block"&gt;[Service]
Environment="HTTP_PROXY=http://proxy.example.com:8080/"&lt;/pre&gt;
&lt;p&gt;Reading the &lt;a class="reference external" href="https://docs.docker.com/engine/admin/systemd/"&gt;docker documentation&lt;/a&gt;, it's very clear:
&lt;strong&gt;If you have internal Docker registries that you need to contact without proxying you can specify them via the NO_PROXY environment variable&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let's add the NO_PROXY variable:&lt;/p&gt;
&lt;pre class="literal-block"&gt;[Service]
Environment="HTTP_PROXY=http://proxy.example.com:8080/" "NO_PROXY=localhost,127.0.0.1,mygitlab.example.com"&lt;/pre&gt;
&lt;p&gt;Flush the changes and restart the docker daemon:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ sudo systemctl daemon-reload
$ sudo systemctl restart docker&lt;/pre&gt;
&lt;p&gt;Now let's try to login again:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ docker login mygitlab.example.com:4567
Username: user
Password:
Error response from daemon: Get https://mygitlab.example.com:4567/v1/users/: x509: certificate signed by unknown authority&lt;/pre&gt;
&lt;p&gt;This error is easy to fix (after googling). I have to add the self-signed certificate at the OS level.
On my Ubuntu machine:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ sudo cp mygitlab.example.com.crt /usr/local/share/ca-certificates/
$ sudo update-ca-certificates
$ sudo systemctl restart docker

$ docker login mygitlab.example.com:4567
Username: user
Password:
Login Succeeded&lt;/pre&gt;
&lt;p&gt;Yes! :-)&lt;/p&gt;
&lt;p&gt;I can now push docker images to my GitLab Container Registry!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Setting GitLab Container Registry should have been easy but my proxy
settings made me lost quite some time... The proxy environment variables (HTTP_PROXY, NO_PROXY...)
are not taken into account by the docker commands. The docker daemon has to be configured
specifically. Something to remember!&lt;/p&gt;
&lt;p&gt;Note that this was with docker 1.11.2. When trying the same command on my Mac with docker 1.12.1, I got a nicer error message:&lt;/p&gt;
&lt;pre class="literal-block"&gt;$ docker --version
Docker version 1.12.1, build 6f9534c
$ docker login foo
Username: user
Password:
Error response from daemon: Get https://foo/v1/users/: dial tcp: lookup foo on xxx.xxx.xx.x:53: no such host&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>ci</category><category>docker</category><category>git</category><category>gitlab</category><category>synology</category><guid>http://beenje.github.io/blog/posts/gitlab-container-registry-and-proxy/</guid><pubDate>Wed, 21 Sep 2016 20:10:06 GMT</pubDate></item></channel></rss>